{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMECeFAw+ZKV+skzDpdziQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinmichalsmolen/adam/blob/main/CIFAR10_MAX_MODEL_DOBRZE_START.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwf0XzaKyz8X",
        "outputId": "1fc6b7c8-9dce-4481-d39d-f2ca5d34431a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun 18 00:03:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    30W /  70W |   4617MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Training model with Adagrad optimizer...\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip_4 (RandomFlip)  (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " random_zoom_4 (RandomZoom)  (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_21 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10 as dataset\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, MaxPooling2D, Dense, Flatten, Conv2D\n",
        "from keras.layers import BatchNormalization, RandomZoom, RandomFlip\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.optimizers import Adagrad, RMSprop, SGD, Adadelta, Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_data():\n",
        "    (X_train, y_train), (X_test, y_test) = dataset.load_data()\n",
        "    # Konwersja wektorów y_train i y_test do formatu one-hot\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "def normalize_pixels(tmp_train, tmp_test):\n",
        "    # Zamiana na zmiennoprzecinkowe\n",
        "    X_train = tmp_train.astype('float32')\n",
        "    X_test = tmp_test.astype('float32')\n",
        "    # Normalizacja\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "    return X_train, X_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_data()\n",
        "X_train, X_test = normalize_pixels(X_train, X_test)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define model with dropout\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(RandomFlip(\"horizontal\", input_shape=(32, 32, 3)))  # Zmiana wymiarów wejściowych\n",
        "    model.add(RandomZoom(0.2, 0.2))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define training settings\n",
        "batch_size = 64\n",
        "epochs = 50\n",
        "optimizer_names = ['Adagrad', 'RMSprop', 'SGDNesterow', 'Adadelta', 'Adam']\n",
        "optimizers = [Adagrad(), RMSprop(), SGD(nesterov=True), Adadelta(), Adam()]\n",
        "\n",
        "# Train models with different optimizers\n",
        "history = {}\n",
        "for optimizer_name, optimizer in zip(optimizer_names, optimizers):\n",
        "    print(f'Training model with {optimizer_name} optimizer...')\n",
        "    model = create_model()\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    history[optimizer_name] = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "                                        verbose=0, validation_data=(X_test, y_test))\n",
        "    train_accuracy = model.evaluate(X_train, y_train)\n",
        "    test_accuracy = model.evaluate(X_test, y_test)\n",
        "    print('Dokładności klasyfikacji na materiale treningowym  = ', train_accuracy)\n",
        "    print('Dokładności klasyfikacji na materiale testowym  = ', test_accuracy)\n",
        "\n",
        "# Plot training loss for all models on one graph\n",
        "plt.figure(figsize=(10, 6))\n",
        "for optimizer_name in optimizer_names:\n",
        "    plt.plot(history[optimizer_name].history['loss'], label=optimizer_name)\n",
        "plt.title('Training Loss for Different Optimizers')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for optimizer_name in optimizer_names:\n",
        "    plt.plot(history[optimizer_name].history['val_loss'], label=optimizer_name)\n",
        "plt.title('Validation Loss for Different Optimizers')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for optimizer_name in optimizer_names:\n",
        "    plt.plot(history[optimizer_name].history['accuracy'], label=optimizer_name)\n",
        "plt.title('Accuracy for Different Optimizers')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for optimizer_name in optimizer_names:\n",
        "    plt.plot(history[optimizer_name].history['val_accuracy'], label=optimizer_name)\n",
        "plt.title('Validation Accuracy for Different Optimizers')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}